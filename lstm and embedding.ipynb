{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "# vocab_size is the number of words in your train, val and test set\n",
    "# vector_size is the dimension of the word vectors you are using\n",
    "\n",
    "vocab_size=25002\n",
    "vector_size=100\n",
    "\n",
    "embed = nn.Embedding(vocab_size, vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = torch.LongTensor([40,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6907,  0.2885,  1.4397,  2.1910, -2.1546,  0.5047,  0.2103, -0.2791,\n",
       "         -1.0564,  0.5220,  1.2948, -0.5820,  0.5073, -0.0403,  0.7851, -0.5532,\n",
       "          1.8118,  0.0442,  1.8285,  0.7730,  0.3019,  1.2317, -0.6490,  1.6030,\n",
       "         -0.1088,  1.0509, -0.6375, -0.5121,  1.6826, -1.0671, -0.2840,  1.6584,\n",
       "         -0.5461,  1.2828, -0.8427, -0.6241,  1.5092, -0.2173,  0.6912, -0.0040,\n",
       "         -0.3063, -1.5882, -0.0471, -1.8819,  0.0270,  0.1458, -0.1377,  0.0088,\n",
       "          0.7891, -0.4372,  0.7212, -0.1882,  2.6015, -1.4048, -0.8014,  0.3659,\n",
       "         -1.0742, -0.0092,  1.2280,  0.3879,  0.3928,  0.7381, -0.9672, -0.6976,\n",
       "          1.5110,  0.0171, -0.0420, -0.1572, -0.7460, -0.6266, -1.4129, -0.4456,\n",
       "          0.0652,  0.0281,  0.7886, -0.3335,  0.5035,  0.5686,  1.7987, -0.4270,\n",
       "         -0.3612, -0.1875, -0.5128,  0.6400, -0.4544, -0.1112, -0.4476, -0.1953,\n",
       "         -0.5148, -0.3685, -1.2785,  0.2937, -0.6769,  0.1851, -0.3565,  0.6629,\n",
       "          1.4697, -1.2253,  1.1675, -1.1205],\n",
       "        [-0.3020, -0.8265, -1.2247, -1.4160, -0.2212,  0.2581, -1.0384,  1.0542,\n",
       "         -0.1555,  0.5790,  0.4235, -0.7350,  0.0870,  0.6640, -3.0184,  1.4871,\n",
       "         -0.8668,  2.3160, -0.5745, -1.5143, -0.1061,  0.2545, -0.3388, -0.6246,\n",
       "          0.5236,  1.3638, -0.0385, -1.6902,  0.8235, -0.0256, -0.5831,  1.7491,\n",
       "         -0.1825, -1.5169, -0.4504,  0.4947, -2.1934,  0.0597,  1.9158, -0.5240,\n",
       "          1.5504,  1.1487, -0.2874,  0.7394, -0.7498, -1.0311,  0.2165,  0.7341,\n",
       "         -0.4699,  1.3403,  2.9209,  2.0149,  0.5413, -1.3676,  1.1870,  0.2334,\n",
       "          0.7195, -0.0821, -1.7302,  2.1767,  0.1098,  2.2203,  0.4002, -0.3448,\n",
       "          1.0233, -0.1315,  0.0697,  0.1629,  0.9394, -0.5762, -0.1702,  0.9853,\n",
       "          0.4783,  1.5999,  0.0456, -0.3285,  0.1026,  0.4848, -2.7501,  1.2788,\n",
       "         -0.5816,  0.3549,  0.2984, -1.1964, -1.7495, -0.0086, -0.6129, -0.5765,\n",
       "          1.0514,  0.9365,  0.7434,  0.3941,  0.4416,  0.5762,  0.1159,  0.5552,\n",
       "         -0.9614,  0.8910, -0.0997, -0.2557]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.6784, -0.4624, -1.4364,  ..., -0.9431,  0.5979,  1.3909],\n",
       "         [ 0.7087, -1.8524,  1.2147,  ..., -0.0700,  1.1300, -1.7908],\n",
       "         [ 0.0802, -0.1246,  0.2650,  ...,  1.9817,  1.6588,  0.4340],\n",
       "         ...,\n",
       "         [ 0.6061,  1.1936,  0.7391,  ..., -0.0692, -1.4160,  0.6841],\n",
       "         [ 1.2195,  1.0505, -0.7947,  ...,  1.7236, -0.8602,  1.9560],\n",
       "         [-0.3548, -0.8418,  0.6386,  ..., -0.5770,  1.0387,  1.4710]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(embed.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(lstm , self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(in_size , classes_no , batch_first=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        print(f'x size: {x.size()}')\n",
    "        \n",
    "        out , _ = self.lstm(x)\n",
    "        \n",
    "        print(out[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size 10,3,7\n",
    "batch_size=3\n",
    "time_steps=10\n",
    "in_size=5\n",
    "classes_no=2\n",
    "\n",
    "input_seq = torch.randn(batch_size , time_steps , in_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size: torch.Size([3, 10, 5])\n",
      "tensor([[ 0.2158,  0.6023],\n",
      "        [ 0.1530, -0.0690],\n",
      "        [ 0.1036,  0.3327]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "out=  model(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
